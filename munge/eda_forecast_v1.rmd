---
title: "Influencer Engagement Analysis"
author: "Esteban Castillo"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    theme: flatly
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.width = 10,
  fig.height = 6
)
```

## Introduction

This document analyzes influencer engagement data, focusing on the relationship between potential reach and engagement rates, and forecasting video plays using various time series models.

## Data Preparation

```{r load-libraries}
# Load required libraries
library(forecast)
library(ggplot2)
library(dplyr)
library(lubridate)
library(glue)
library(TTR)
library(xts)
library(scales)
```

```{r load-data}
# Load and prepare the influencer data
df_full <- read.csv('~/rug/thesis/data/influencer_sample010525.csv') %>% 
  mutate_at(c('comments', 'video_views', 'engagements', 'video_plays', 'shares', 'potentialReach'), as.numeric) %>% 
  filter(!is.na(engagements) & potentialReach > 0) %>% 
  mutate(engagements_rate = engagements/potentialReach)
```

## Engagement Rate Analysis

### Correlation Analysis

```{r correlation}
# Calculate correlation between engagement rate and potential reach
cor(df_full$engagements_rate, df_full$potentialReach, use = 'complete.obs')
```

### Linear Regression Model

```{r linear-model}
# Create linear regression model
model_reg <- lm(engagements_rate ~ potentialReach, data = df_full)
summary(model_reg)

# Add predictions to the dataset
df_full$predicted <- predict(model_reg, newdata = df_full)
```

### Visualization: Actual vs Predicted

```{r actual-vs-predicted}
# Plot actual vs predicted engagement rates
ggplot(df_full, aes(x = predicted, y = engagements_rate)) +
  geom_point(alpha = 0.6) +  # scatter plot
  geom_abline(intercept = 0, slope = 1, color = "blue", linetype = "dashed") +  # 45-degree line
  labs(title = "Predicted vs Actual Engagement Rate",
       x = "Predicted Engagement Rate",
       y = "Actual Engagement Rate") +
  scale_y_continuous(limits = c(0, 1)) +
  theme_minimal()
```

### Residual Analysis

```{r residuals}
# Extract residuals from the model
resid_vals <- residuals(model_reg)
model_data <- model.frame(model_reg)
model_data$residuals <- resid_vals

# Plot residuals vs potential reach
ggplot(model_data, aes(x = potentialReach, y = residuals)) +
  geom_point(alpha = 0.6) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Residuals vs Potential Reach",
       x = "Potential Reach",
       y = "Residuals") +
  scale_x_log10(labels = scales::comma_format()) +
  theme_minimal()
```

## Time Series Forecasting

### Forecast Function

```{r forecast-function}
# Function to plot forecasts for different models
plot_forecast <- function(x_ts, model, model_name, metric_name, h = 10, ci_width = 0.05) {
  
  n_obs <- length(x_ts)
  time_index <- seq_len(n_obs)
  future_index <- seq(n_obs + 1, n_obs + h)
  
  # Historical DataFrame
  historical_df <- data.frame(
    time = time_index,
    engagement_rate = as.numeric(x_ts)
  )
  
  if (is.numeric(model)) {
    # Proper forecasting model
    last_value <- tail(model[!is.na(model)], 1) # use last non-NA
    
    forecast_values <- rep(last_value, h)
    
    forecast_df <- data.frame(
      time = future_index,
      forecast = forecast_values,
      lower_80 = forecast_values * (1 - ci_width),
      upper_80 = forecast_values * (1 + ci_width),
      lower_95 = forecast_values * (1 - ci_width * 2),
      upper_95 = forecast_values * (1 + ci_width * 2)
    )
    
  } else {
    # TTR models (SMA, EMA, etc.) are just smoothed numeric vectors
    fc <- forecast::forecast(model, h = h, bootstrap = T, PI = T)
    
    forecast_df <- data.frame(
      time = future_index,
      forecast = as.numeric(fc$mean),
      lower_80 = as.numeric(fc$lower[, 1]),
      upper_80 = as.numeric(fc$upper[, 1]),
      lower_95 = as.numeric(fc$lower[, 2]),
      upper_95 = as.numeric(fc$upper[, 2])
    )
  }
  
  # Final Plot (consistent for all models)
  ggplot() +
    geom_line(data = historical_df, aes(x = time, y = engagement_rate), color = "black") +
    geom_line(data = forecast_df, aes(x = time, y = forecast), color = "blue") +
    geom_ribbon(data = forecast_df, aes(x = time, ymin = lower_95, ymax = upper_95), fill = "lightblue", alpha = 0.4) +
    geom_ribbon(data = forecast_df, aes(x = time, ymin = lower_80, ymax = upper_80), fill = "lightgrey", alpha = 0.4) +
    labs(title = glue::glue("{metric_name} Forecast"),
         subtitle = glue::glue("Model {model_name}"),
         x = "Post Index",
         y = metric_name) +
    theme_minimal()
}
```

### Load Test Data

```{r load-test-data}
# Load test data for forecasting
df_temp <- read.csv('~/rug/thesis/data/test_vv230225.csv') %>% 
  mutate(
    engagement_rate = (reactions + comments) / potentialReach,
    loss = -reactions / potentialReach,
    published_date = lubridate::as_date(publishedDate)
  ) %>% 
  filter(!is.na(video_plays))

# Set forecast horizon
h <- 6

# Extract time series
x_ts <- df_temp %>% pull(video_plays)
```

### Model 1: ARIMA

```{r arima-model}
# Create and plot ARIMA model
model_arima <- forecast::auto.arima(x_ts)
plot_forecast(x_ts, model_arima, model_name = 'Auto ARIMA', metric_name = 'Video plays', h = h)
```

### Model 2: Exponential Moving Average

```{r ema-model}
# Create and plot EMA model
model_ema <- TTR::EMA(x_ts)
plot_forecast(x_ts, model_ema, model_name = 'EMA', metric_name = 'Video plays', h = h)
```

### Model 3: Exponential Smoothing

```{r ets-model}
# Create and plot ETS model
model_ets <- forecast::ets(x_ts)
plot_forecast(x_ts, model_ets, model_name = 'ETS', metric_name = 'Video plays', h = h)
```

### Model 4: Theta Method

```{r theta-model}
# Create and plot Theta model
model_theta <- forecast::thetaf(x_ts)
plot_forecast(x_ts, model_theta, model_name = 'Theta', metric_name = 'Video plays', h = h)
```

### Model 5: Linear Regression

```{r lm-model}
# Convert to time series object
x_xts <- xts::as.xts(x_ts, order.by = df_temp$published_date)
x_ts_ts <- ts(as.numeric(x_xts), 
              frequency = 365, 
              start = c(as.numeric(format(start(x_xts), "%Y")), 
                        as.numeric(format(start(x_xts), "%j"))))

# Create and plot linear trend model
model_lm <- forecast::tslm(x_ts_ts ~ trend)
plot_forecast(x_ts, model_lm, model_name = 'Linear Regression', metric_name = 'Video plays', h = h)
```

### Model 6: Autoregressive Model

```{r ar-model}
# Define AR function and create model
ar_fun <- function(x, h){forecast(Arima(x, order = c(4, 0, 0)), h = h)}
model_ar <- ar_fun(x_ts, h)
plot_forecast(x_ts, model_ar, model_name = 'AR (4)', metric_name = 'Video plays', h = h)
```

### Model 7: Neural Network

```{r nnet-model}
# Create and plot Neural Network model
model_nnet <- nnetar(x_ts, h)
plot_forecast(x_ts, model_nnet, model_name = 'Neural Net Autoregressive', metric_name = 'Video plays', h = h)
```

## Model Evaluation

```{r model-evaluation}
# Time series cross-validation
test_metrics <- forecast::tsCV(x_ts, ar_fun, h = 6)

# Calculate error metrics
# RMSE
rmse <- sqrt(colMeans(test_metrics^2, na.rm = TRUE))

# MAE
mae <- colMeans(abs(test_metrics), na.rm = TRUE)

# MAPE
n <- length(x_ts)
mape <- numeric(6)

for (h in 1:6) {
  # Predicted errors are x_ts[t+h] - forecast[t]
  actuals <- x_ts[(h + 1):n]
  forecasts <- x_ts[1:(n - h)] + test_metrics[1:(n - h), h]  # reconstruct forecast = actual - error
  mape[h] <- mean(abs((actuals - forecasts) / actuals), na.rm = TRUE) * 100
}

# Final metrics table
metrics <- data.frame(
  Horizon = 1:6,
  RMSE = rmse,
  MAE = mae,
  MAPE = mape
)

print(metrics)
```

## Time series Cross validation
We test each metric and source against different forecasting methods to see which metrics are predictable as a time series problem.
```{r}
df=read.csv('~/rug/thesis/thesis/cache/summary_df_2505061047.csv')

df_sum=df %>% 
  filter(test_MeanAbsolutePercentageError<200) %>% 
  group_by(source,metric_name,model_name) %>% summarise(across(contains('test_'),mean))
df_sum %>% ggplot(aes(x=model_name,y=test_MeanAbsolutePercentageError))+
  geom_col()+facet_wrap(source~metric_name,scales = 'free_y')+scale_y_continuous(labels = scales::number_format())

df
```

## MAPE by source-metric

```{r}
df_sum %>% ggplot(aes(x=model_name,y=test_MeanAbsolutePercentageError))+
  geom_col()+facet_wrap(source~metric_name,scales = 'free_y')+scale_y_continuous(labels = scales::number_format())+theme(axis.text.x = element_text(angle=90))
```

